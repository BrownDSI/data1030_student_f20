{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mud card and piazza questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Will feature engineering always improve the performance of model because we take into account more features and relations between features?**\n",
    "    - No, there is no guarantee that the new features will improve your model\n",
    "    - if you use certain techniques (e.g., random forest), it will not make your model performance worse.\n",
    "    - the performance of certain other techniques (e.g., nearest neighbors) could in fact decline if too many non-predictive features are added - more on this later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **I was a little confused about the automatic feature engineering both conceptually and code**\n",
    "- **Feature engineering was most confusing for me. Maybe if we went over another example?**\n",
    "\n",
    "- **I am having trouble working through an real world example for feature engineering, could you walk through a data set and example how in context, the feature engineering improved the predictive power of what we are looking to solve?**\n",
    "    - I recommend you try it with the adult dataset\n",
    "    - native country feature: instead of one-hot encoding, look up what the GDP of those countries were in 1990 and replace the country name with the GDP value\n",
    "    - that's a continuous feature and it will likely improve the model performance because citizens from a rich country will only migrate to the USA if they earn more than what they would earn in their home countries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **In regards to Feature engineering for automatic vs manual. Which one do you think is more useful for this class and in general?**\n",
    "    - manual feature engineering\n",
    "    - it has the best chances of improving your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Should we try manual feature engineering first? If we know enough about the dataset to select preferred features immediately and throw out the rest, isn't that an efficient way to make this decision?**\n",
    "    - often you don't know in advance which the preferred features are\n",
    "    - sometimes you are surprised and features that you wouldn't think will be important\n",
    "    - we will talk about feature importance metrics to measure how predictive each feature is later"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Quiz 5 is a hard question for me to understand it conceptually. Hope to discuss it in class.**\n",
    "- **what is the degree in the polynomial transform signify? Why wasn't abc included as a column in the last quiz?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **\"For PolynomialFeatures, the degree refers to the maximum degree of all combinations of different features right? So if we set degree = 3 in the last quiz, we should have abc, ab^2. b^3, etc.**\n",
    "    - yes, that's right but run the code, print the feature names to verify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **So the meaning of doing auto feature is to try common feature engineering on the data set? And polynomialFeatures is only one of the auto feature method? What are other options? Are we going to dig in more on this?**\n",
    "    - we won't dig more into this but feel free to check out [sklearn.preprocessing](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Can you please expand a bit more on manual feature engineering and in what situations you could or should attempt to do this? I understand that it requires more domain-specific knowledge and a greater amount of work, but I guess I am unclear on whether or not it would be appropriate to attempt manual feature engineering without extensive knowledge. You gave us some examples on what can help us engineer our features better but I am not sure if this is just meant to show us what we could do if we were in a good position to do manual feature engineering, or if it is supposed to help us if we wanted to do it but aren't as knowledgable about the relevant domain. Would it be too risky to attempt manual feature engineering if you are not an expert on the subject?**\n",
    "    - feature engineering is not risky\n",
    "    - you could engineer a feature, check if/how much it influences the evaluation metric of the model\n",
    "    - if it helps, keep it\n",
    "    - if it doesn't help, drop it\n",
    "    - you could/should always attempt it\n",
    "    - as you work more with the data and regularly meet with subject matter experts, slowly you willl become a subject matter expert too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Unless we are specifically interested in determining which variables correlate only linearly with the target variable, what reason do we have for using the F-test? Mutually information seems as though it should generally be a much better estimate.**\n",
    "    - sometimes you know in advance that you only want to develop a linear or logistic regression model in which case the F-test is better to use.\n",
    "    - if you know that you'll train more complex models, go for mutual info."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **We looked at correlations between features (comparison between linear and sine correlations, etc.). It feels like it should be possible to calculate these correlations through EDA when given a dataset, but what if the correlation is not straightforward? (Like a trignometric correlation, or a more complex polynomial).**\n",
    "    - mutual information captures non-linear correlations, see the example with the sin-wave"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Bit confused about Quiz 4. I managed to calculate the different f-score, p-values and mi. How can we use these to access which columns of X are the most important? (I think this is a coding issue because my graphs showed x1, x2, x3)**\n",
    "- **Could we go over the coding procedure for Quiz 4? How do we extract the name of the feature with the highest F score?**\n",
    "- **In terms of code, how do you get the column names from the K Best feature selection (particularly for a model with many features)?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **In the video you mentioned that we should choose whether we are interested in linear relationships vs non-linear relationships before we start the process of feature selection.¬† Is it ever wise to check both f-test and mutual information before we decide on a model or features?¬† Can we choose the best features from both f-test and mutual info and customize the model based off these decisions?**\n",
    "    - yes, absolutely!\n",
    "    - you could for example calculate the average feature rank based on the f-test and MI and select features based on that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **\"What about the case of multicollinearity? When would we discard K Best features that are highly correlated, in order to get a simpler model?**\n",
    "    - also in preprocessing\n",
    "    - you should consider which of the highly correlated features you keep though. it's not an easy choice and as far as I know, there is no good data-driven way to make this decision"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **I am really confused about the feature selection process and what its overall purpose is. Perhaps some more concrete examples would help.**\n",
    "    - sometimes you have a lot of features but comperatively low number of features (e.g., in genetics)\n",
    "    - then you need to select features before you start training models\n",
    "    - most often however you select features based on feature importance metrics derived using ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Does a regression analysis only work if one continuous feature is missing variables? What if there are multiple?**\n",
    "    - I assume you mean multivariate imputation\n",
    "    - it works if multiple features have missing values, the technique is a bit more complicated then."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Is there a comprehensive test to tell whether data is MCAR, MAR, or MNAR, or does that have to be done with more a more interpretive hands-on look at the data?**\n",
    "    - as far as I know, there is no comprehensive test to distinguish MCAR, MAR, MNAR\n",
    "    - Little's test can tell you if MAR is present in your data, but it can't distinguish MAR from MCAR and MNAR\n",
    "    - a hands-on look might help and give you hints but it is not comprehensive"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Can imputation for single variable be done using strategies other than \"mean\"? Are they more effective to avoid the std. dev. changing?**\n",
    "- **Could you please explain more in detail when should we use simpleImputer and which strategy should I apply for, like mean or median? In addition, when should we iterative imputer. What's pros and con for both of them?**\n",
    "    - if you really want to impute, do multivariate imputation, that's the best.\n",
    "    - mean and median imputation will always skew your dataset because it reduces the standard deviation or generally the shape of the feature's dsitribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **What are some approaches that we may handle MNAR although it's tough? Or any tips?**\n",
    "- **Im wondering is there anything at all that can help account for MNAR missingness or do we just have to accept that the model will be biased? are these biased models even still useful?**\n",
    "- **If it doesn't make sense to impute some value (like garage area if there is no garage), then how can we feel safe imputing it? If we can't, then how are we supposed to build a model on the dataset?**\n",
    "    - \"Every model is wrong but some are useful.\"\n",
    "    - We will cover advanced techniques in November that can deal with MNAR."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **For the name of missing data type, I think what matter is what is the missing data correlated to. So I don't see how 'random' it is. Isn't it really just no correlation, correlated with other features and correlated with itself?**\n",
    "    - there is a gray zone in between, it's not just no correlation or perfect correlation\n",
    "    - partial correlation: a mix of MCAR and MAR, or a mix of MAR and MNAR, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **How do we know in which category is which when representing categories with numbers? For example, 0 and 1, which is Yes and which is no? Which is female, which is male? Which means NA, which means not?**\n",
    "    - the feature names encode that information\n",
    "    - the feature name will be 'sex_female' and 'sex_male' or 'sex_NA' for example after one-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **In the following calls, I have no idea what the purpose of the strings are (eg. 'imputer2', 'ordinal', 'num', 'cat', 'ord'). Are these strings calling a specific function, or are they just names you are giving them?**\n",
    "``` python\n",
    "preprocessor = ColumnTransformer(\n",
    "transformers=[\n",
    "('num', numeric_transformer, num_ftrs),\n",
    "('cat', categorical_transformer, cat_ftrs),\n",
    "('ord', ordinal_transformer, ordinal_ftrs)])\n",
    "```\n",
    "    - just names I gave them so we can refer to them by name later if necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Can a problem ever be classification and regression?**\n",
    "    - Not really, sometimes a problem can be solved with both classification and regression but you need to decide whether you apply a classification or a regression model to the problem, or try both.\n",
    "    - You could have classification problems with more than two classes\n",
    "    - You could have multiple target variables some of them regression, some of them classification\n",
    "    - There is also ranking which is a different type of ML problem not often used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
