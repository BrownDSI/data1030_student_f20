{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem set 4\n",
    "\n",
    "**Problem 0** (-2 points for every missing green OK sign. If you don't run the cell below, that's -14 points.)\n",
    "\n",
    "Make sure you are in the DATA1030 environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[42m[ OK ]\u001b[0m Python version is 3.7.8 | packaged by conda-forge | (default, Jul 31 2020, 02:37:09) \n",
      "[Clang 10.0.1 ]\n",
      "\n",
      "\u001b[42m[ OK ]\u001b[0m numpy version 1.18.5 is installed.\n",
      "\u001b[42m[ OK ]\u001b[0m matplotlib version 3.2.2 is installed.\n",
      "\u001b[42m[ OK ]\u001b[0m sklearn version 0.23.1 is installed.\n",
      "\u001b[42m[ OK ]\u001b[0m pandas version 1.0.5 is installed.\n",
      "\u001b[42m[ OK ]\u001b[0m xgboost version 1.1.1 is installed.\n",
      "\u001b[42m[ OK ]\u001b[0m shap version 0.35.0 is installed.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from distutils.version import LooseVersion as Version\n",
    "import sys\n",
    "\n",
    "OK = '\\x1b[42m[ OK ]\\x1b[0m'\n",
    "FAIL = \"\\x1b[41m[FAIL]\\x1b[0m\"\n",
    "\n",
    "try:\n",
    "    import importlib\n",
    "except ImportError:\n",
    "    print(FAIL, \"Python version 3.7 is required,\"\n",
    "                \" but %s is installed.\" % sys.version)\n",
    "\n",
    "def import_version(pkg, min_ver, fail_msg=\"\"):\n",
    "    mod = None\n",
    "    try:\n",
    "        mod = importlib.import_module(pkg)\n",
    "        if pkg in {'PIL'}:\n",
    "            ver = mod.VERSION\n",
    "        else:\n",
    "            ver = mod.__version__\n",
    "        if Version(ver) == min_ver:\n",
    "            print(OK, \"%s version %s is installed.\"\n",
    "                  % (lib, min_ver))\n",
    "        else:\n",
    "            print(FAIL, \"%s version %s is required, but %s installed.\"\n",
    "                  % (lib, min_ver, ver))    \n",
    "    except ImportError:\n",
    "        print(FAIL, '%s not installed. %s' % (pkg, fail_msg))\n",
    "    return mod\n",
    "\n",
    "\n",
    "# first check the python version\n",
    "pyversion = Version(sys.version)\n",
    "if pyversion >= \"3.7\":\n",
    "    print(OK, \"Python version is %s\" % sys.version)\n",
    "elif pyversion < \"3.7\":\n",
    "    print(FAIL, \"Python version 3.7 is required,\"\n",
    "                \" but %s is installed.\" % sys.version)\n",
    "else:\n",
    "    print(FAIL, \"Unknown Python version: %s\" % sys.version)\n",
    "\n",
    "    \n",
    "print()\n",
    "requirements = {'numpy': \"1.18.5\", 'matplotlib': \"3.2.2\",'sklearn': \"0.23.1\", \n",
    "                'pandas': \"1.0.5\",'xgboost': \"1.1.1\", 'shap': \"0.35.0\"}\n",
    "\n",
    "# now the dependencies\n",
    "for lib, required_version in list(requirements.items()):\n",
    "    import_version(lib, required_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit, GroupKFold, StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 1a** (3 points)\n",
    "\n",
    "You will work with the diabetes dataset in Problem 1 and you will split the data and preprocess it to get ready for training an ML model. First, read in the dataset into a pandas dataframe using the tab delimited file linked at [this page](https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grading suggestion:\n",
    "- 3 points if they read in the file correctly using the delimiter argument\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>BMI</th>\n",
       "      <th>BP</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "      <th>S4</th>\n",
       "      <th>S5</th>\n",
       "      <th>S6</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>32.1</td>\n",
       "      <td>101.0</td>\n",
       "      <td>157</td>\n",
       "      <td>93.2</td>\n",
       "      <td>38.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.8598</td>\n",
       "      <td>87</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>21.6</td>\n",
       "      <td>87.0</td>\n",
       "      <td>183</td>\n",
       "      <td>103.2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.8918</td>\n",
       "      <td>69</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>30.5</td>\n",
       "      <td>93.0</td>\n",
       "      <td>156</td>\n",
       "      <td>93.6</td>\n",
       "      <td>41.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.6728</td>\n",
       "      <td>85</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>25.3</td>\n",
       "      <td>84.0</td>\n",
       "      <td>198</td>\n",
       "      <td>131.4</td>\n",
       "      <td>40.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.8903</td>\n",
       "      <td>89</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>192</td>\n",
       "      <td>125.4</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.2905</td>\n",
       "      <td>80</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGE  SEX   BMI     BP   S1     S2    S3   S4      S5  S6    Y\n",
       "0   59    2  32.1  101.0  157   93.2  38.0  4.0  4.8598  87  151\n",
       "1   48    1  21.6   87.0  183  103.2  70.0  3.0  3.8918  69   75\n",
       "2   72    2  30.5   93.0  156   93.6  41.0  4.0  4.6728  85  141\n",
       "3   24    1  25.3   84.0  198  131.4  40.0  5.0  4.8903  89  206\n",
       "4   50    1  23.0  101.0  192  125.4  52.0  4.0  4.2905  80  135"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the data in this cell\n",
    "df = pd.read_csv(\"https://www4.stat.ncsu.edu/~boos/var.select/diabetes.tab.txt\", sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Write you answer in this cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 1b** (6 points)\n",
    "\n",
    "Answer the following questions with 1-2 paragraphs.\n",
    "\n",
    "Q1: Is the dataset IID or not? Why?\n",
    "\n",
    "Q2: Please decide what fraction of points will be in each set and explain your decision in a paragraph or two.\n",
    "\n",
    "Q3: Please explain in a paragraph or two why it is important to fit the preprocessors on the training set only.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grading suggestion:\n",
    "- 2 points if they correctly argue that the dataset is IID.\n",
    "- 2 points for a correct argument. 60-20-20 is best, I'd still be OK with 80-10-10 if they have a reasonable argument.\n",
    "- 2 points for a good Q3 explanation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 1c** (11 points)\n",
    "\n",
    "Based on your answers above, please perform a basic split and create training, validation, and test sets.\n",
    "\n",
    "Now that you have three sets, you can preprocess the data. Please decide for each feature which preprocessor you will use (no need to write text). Fit those preprocessors on the training set, then transform the sets.\n",
    "\n",
    "We discussed in class that it is important to split the data using various different random states so you can determine at the  end of the ML pipeline how much uncertainty in the test score the random splitting causes. Please use 10 random states and split/preprocess the data 10 times. \n",
    "\n",
    "Please make sure that your code is reproducable. The best way to check that is to print out which points are in e.g., the training set and rerun the cell a couple of times. If the same points are in the same set after every rerun, your code is reproducable. \n",
    "\n",
    "A couple of suggestions how you could structure your code is available below. \n",
    "\n",
    "\n",
    "One option:\n",
    "```python\n",
    "\n",
    "random_states = [...,...,...] # list of 10 numbers\n",
    "\n",
    "for random_state in random_states:\n",
    "    # whenever you need to set the random state, use `random_state`\n",
    "    \n",
    "    # split the data\n",
    "    \n",
    "    # preprocess the data\n",
    "    \n",
    "    # print stuff out to make sure your code is reproducable\n",
    "    \n",
    "```\n",
    "\n",
    "Second option:\n",
    "```python\n",
    "\n",
    "\n",
    "for i in range(0,10):\n",
    "    random_state = 42 * i # feel free to replace 42 with your magic number.\n",
    "                          # the only important thing is that random_state has a different value in each iteration.\n",
    "    \n",
    "    # split the data\n",
    "    \n",
    "    # preprocess the data\n",
    "    \n",
    "    # print stuff out to make sure your code is reproducable\n",
    "    \n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grading suggestion:\n",
    "\n",
    "- 3 points for correctly splitting with train_test_split and setting the random_state\n",
    "- 2 points for correctly using a one-hot encoder on the gender and either the standard scaler or the min-max scaler on the rest (deduct a point if they also preprocess the target variable. in regression, the target variable stays as is)\n",
    "- 3 points if the fit the preprocessors to the training set and then transform everything\n",
    "- 3 points for correctly looping through 10 random states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SEX_1  SEX_2       AGE       BMI        BP        S1        S2        S3  \\\n",
      "0    0.0    1.0 -0.101364 -0.835511 -0.948322 -1.661115 -1.549201 -0.698947   \n",
      "1    0.0    1.0  1.014762  1.252631  1.475618  0.269567  0.435301 -0.473754   \n",
      "2    0.0    1.0  0.047453  1.275084 -0.066889  1.263300  1.308739 -1.224396   \n",
      "3    0.0    1.0 -0.175772  3.587757  0.300374  0.610275  0.705039 -0.473754   \n",
      "4    1.0    0.0 -0.994265  0.129974  0.226922 -0.780951 -0.367491 -0.398690   \n",
      "\n",
      "         S4        S5        S6  \n",
      "0 -0.798531  0.205609 -0.189521  \n",
      "1  0.701191  0.443799  0.537180  \n",
      "2  2.200913  1.393977  2.475052  \n",
      "3  0.701191  0.679407  0.617925  \n",
      "4 -0.048670 -0.806330 -0.431755  \n",
      "   SEX_1  SEX_2       AGE       BMI        BP        S1        S2        S3  \\\n",
      "0    1.0    0.0 -0.285158  1.213237  1.090432  0.972804  0.610896 -0.385769   \n",
      "1    1.0    0.0  1.412975  1.123179  1.520650 -0.313446 -0.822460 -0.690588   \n",
      "2    0.0    1.0  1.335787 -0.587927  0.229994  1.315804  1.010142  0.604894   \n",
      "3    1.0    0.0  0.409533  0.042480 -0.558741  0.458304  0.211651  1.366942   \n",
      "4    0.0    1.0  2.339230  0.087509  0.588510 -0.599279 -0.154870 -0.995407   \n",
      "\n",
      "         S4        S5        S6  \n",
      "0  0.716097  1.441299  0.112503  \n",
      "1 -0.056785  1.557200  0.729941  \n",
      "2 -0.056785  0.774918  0.377119  \n",
      "3 -0.829667 -0.524620 -1.034166  \n",
      "4  0.716097  0.012686  1.611994  \n",
      "   SEX_1  SEX_2       AGE       BMI        BP        S1        S2        S3  \\\n",
      "0    1.0    0.0 -2.242834 -0.752704 -1.446296 -1.360155 -1.519858  0.154185   \n",
      "1    1.0    0.0 -0.719443 -0.823270 -1.302552  0.459652  0.940420 -0.323698   \n",
      "2    1.0    0.0  1.565644  2.493332  0.566113  0.549151  0.541639  0.393126   \n",
      "3    1.0    0.0  0.499270  1.528930  0.494242 -0.733664 -0.309996 -0.721934   \n",
      "4    1.0    0.0  0.880118 -0.188176 -0.583835  0.549151  0.352387  1.508187   \n",
      "\n",
      "         S4        S5        S6  \n",
      "0 -0.825423  0.035732 -1.713974  \n",
      "1 -0.028973 -0.612360 -1.536481  \n",
      "2 -0.028973  0.035732 -0.116542  \n",
      "3 -0.028973 -0.363983 -0.205288  \n",
      "4 -0.825423 -0.991100 -0.649019  \n",
      "   SEX_1  SEX_2       AGE       BMI        BP        S1        S2        S3  \\\n",
      "0    1.0    0.0  1.472853  1.588195  0.903539  0.542575  0.093274 -0.704646   \n",
      "1    0.0    1.0  1.620333 -0.464722 -0.798242  0.222022  1.183125 -1.387115   \n",
      "2    0.0    1.0  0.661712 -0.677093  1.024574  1.300244  1.522042 -0.628816   \n",
      "3    1.0    0.0  1.177893 -1.432189 -1.356753  0.076317  0.040111  0.963612   \n",
      "4    1.0    0.0 -0.960568 -1.172625 -0.822303 -0.885340 -0.857023  0.053653   \n",
      "\n",
      "         S4        S5        S6  \n",
      "0  0.802287  1.628847  2.337062  \n",
      "1  1.658744 -0.681485  1.282748  \n",
      "2  1.181250  0.779767  1.897764  \n",
      "3 -0.774201 -0.907564  0.052716  \n",
      "4 -0.812097 -0.173543  0.404154  \n",
      "   SEX_1  SEX_2       AGE       BMI        BP        S1        S2        S3  \\\n",
      "0    0.0    1.0 -0.326953 -1.177901 -0.087953 -0.635170 -0.621905  0.326054   \n",
      "1    1.0    0.0 -0.552193  0.908532  1.876533 -0.433899 -0.751037  1.409981   \n",
      "2    0.0    1.0 -0.251872  3.483280  0.275841  0.572456  0.675873 -0.525602   \n",
      "3    1.0    0.0  0.423848  1.241474  1.076187 -0.778935 -1.028671 -0.680449   \n",
      "4    1.0    0.0  1.399890  0.220453  0.857910  1.435046  1.082639  1.022864   \n",
      "\n",
      "         S4        S5        S6  \n",
      "0 -0.790579 -0.355428  0.847817  \n",
      "1 -0.790579 -0.711166 -0.231935  \n",
      "2  0.748190  0.677438  0.598643  \n",
      "3 -0.021194  1.106515 -0.148877  \n",
      "4 -0.021194  0.509224 -0.148877  \n",
      "   SEX_1  SEX_2       AGE       BMI        BP        S1        S2        S3  \\\n",
      "0    1.0    0.0 -0.894386 -1.054249 -0.398884 -0.024483 -0.370912  1.507022   \n",
      "1    1.0    0.0 -0.506223 -0.791389 -0.620540 -1.181023 -1.244386  0.719639   \n",
      "2    1.0    0.0 -1.437814 -0.156145 -0.842197 -1.378482 -1.655433  1.192069   \n",
      "3    1.0    0.0  1.512224 -0.857104 -0.546655 -0.673274 -0.582858  0.247209   \n",
      "4    1.0    0.0  0.425368  0.347669  0.487742 -0.306566 -0.313108 -0.067745   \n",
      "\n",
      "         S4        S5        S6  \n",
      "0 -0.854680 -0.552326  0.424235  \n",
      "1 -0.854680 -1.080061 -2.710703  \n",
      "2 -1.589848 -1.112289 -0.707826  \n",
      "3 -0.854680 -0.601435  0.075909  \n",
      "4 -0.119513  0.249731  0.859643  \n",
      "   SEX_1  SEX_2       AGE       BMI        BP        S1        S2        S3  \\\n",
      "0    1.0    0.0  0.298646  0.601127  1.348327  2.778181  2.104816  1.207471   \n",
      "1    1.0    0.0  0.903354 -0.138936 -0.488605  0.569678  0.422359  1.356768   \n",
      "2    1.0    0.0 -1.137536 -1.688443 -1.689676 -0.791727 -0.764436  0.610285   \n",
      "3    1.0    0.0  0.223057  0.392984  0.147256  0.236890  0.296699 -0.658736   \n",
      "4    0.0    1.0 -0.684005 -0.508968 -0.299967  0.055370 -0.003491  0.087747   \n",
      "\n",
      "         S4        S5        S6  \n",
      "0  0.028225  1.245796 -0.446935  \n",
      "1 -0.775161 -1.027579 -0.630275  \n",
      "2 -0.775161 -1.194840 -3.013695  \n",
      "3  0.831610  0.846522  2.669846  \n",
      "4 -0.252960  0.328308  0.928116  \n",
      "   SEX_1  SEX_2       AGE       BMI        BP        S1        S2        S3  \\\n",
      "0    1.0    0.0 -0.914516 -1.080353 -0.443080 -0.017637 -0.356553  1.547770   \n",
      "1    1.0    0.0  1.547066  0.017521  0.691855  1.027425  0.643025  1.630256   \n",
      "2    1.0    0.0 -1.232140 -0.028224 -0.655880 -0.162784 -0.475708  0.310488   \n",
      "3    1.0    0.0 -0.517487  1.321246 -0.088413 -0.540168 -0.383032  0.557944   \n",
      "4    0.0    1.0  0.911819 -0.256947  0.005929  0.011393  0.775420 -1.174251   \n",
      "\n",
      "         S4        S5        S6  \n",
      "0 -0.851752 -0.558201  0.388195  \n",
      "1 -0.851752 -0.051309  0.388195  \n",
      "2 -0.087939  0.628305 -1.103901  \n",
      "3 -0.851752 -1.320736 -1.269689  \n",
      "4  1.004313 -0.582466  2.128973  \n",
      "   SEX_1  SEX_2       AGE       BMI        BP        S1        S2        S3  \\\n",
      "0    0.0    1.0  1.055050  1.301685  0.624553  0.634667 -0.974010 -1.142803   \n",
      "1    0.0    1.0  0.822383 -0.191888  1.210085 -0.737214 -0.125307 -1.602235   \n",
      "2    0.0    1.0  1.210161 -0.191888  0.999209  1.101690 -0.372567 -0.300509   \n",
      "3    0.0    1.0 -0.496064  1.301685  2.194171  0.284400 -0.339153 -0.070793   \n",
      "4    0.0    1.0 -0.806286 -0.628472 -0.055170  0.488722  0.816954  0.235495   \n",
      "\n",
      "         S4        S5        S6  \n",
      "0  1.518433  2.796213  2.896322  \n",
      "1  1.518433  0.226097 -0.436169  \n",
      "2  0.740788  2.497309 -0.348472  \n",
      "3 -0.036857  1.467198  2.896322  \n",
      "4 -0.036857 -0.868037  1.405471  \n",
      "   SEX_1  SEX_2       AGE       BMI        BP        S1        S2        S3  \\\n",
      "0    1.0    0.0 -1.572322 -1.140604 -0.595860 -1.601938 -1.680277  0.894815   \n",
      "1    1.0    0.0  0.510604 -0.180355 -1.103355  1.484413  1.091517  0.617515   \n",
      "2    0.0    1.0 -0.290521 -0.835071 -0.885857 -0.227109  0.284381 -1.254259   \n",
      "3    1.0    0.0 -1.011534 -1.380667 -1.030856 -0.816321 -0.904425  0.894815   \n",
      "4    1.0    0.0  1.391842  0.037883  0.709128  0.951316  0.584710  1.310765   \n",
      "\n",
      "         S4        S5        S6  \n",
      "0 -1.530494 -1.906716 -2.254958  \n",
      "1 -0.099318  0.886884  0.252545  \n",
      "2  1.331858  0.336218 -1.476767  \n",
      "3 -0.814906 -1.248927 -0.352714  \n",
      "4 -0.814906 -0.057869  0.339010  \n"
     ]
    }
   ],
   "source": [
    "y = df['Y']\n",
    "X = df.loc[:, df.columns != 'Y']\n",
    "\n",
    "scaler_col = list(X.columns)\n",
    "scaler_col.remove('SEX')\n",
    "\n",
    "for i in range(10):\n",
    "    random_state = 42 * i\n",
    "    \n",
    "    # split the data\n",
    "    X_train, X_other, y_train, y_other = train_test_split(X, y, train_size=0.6, random_state=random_state)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_other, y_other, train_size=0.5, random_state=random_state)\n",
    "    \n",
    "    # preprocess the data\n",
    "    enc = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    X_train_ohe = enc.fit_transform(X_train[['SEX']])\n",
    "    X_val_ohe = enc.transform(X_val[['SEX']])\n",
    "    X_test_ohe = enc.transform(X_test[['SEX']])\n",
    "    \n",
    "    X_train_scaler = scaler.fit_transform(X_train[scaler_col])\n",
    "    X_val_scaler = scaler.transform(X_val[scaler_col])\n",
    "    X_test_scaler = scaler.transform(X_test[scaler_col])\n",
    "    \n",
    "    X_train_concat = np.concatenate([X_train_ohe, X_train_scaler], axis=1)\n",
    "    X_val_concat = np.concatenate([X_val_ohe, X_val_scaler], axis=1)\n",
    "    X_test_concat = np.concatenate([X_test_ohe, X_test_scaler], axis=1)\n",
    "    \n",
    "    X_pre_col = list(enc.get_feature_names(['SEX'])) + scaler_col\n",
    "    X_train_pre = pd.DataFrame(X_train_concat, columns=X_pre_col)\n",
    "    X_val_pre = pd.DataFrame(X_val_concat, columns=X_pre_col)\n",
    "    X_test_pre = pd.DataFrame(X_test_concat, columns=X_pre_col)\n",
    "    \n",
    "    # print stuff out to make sure your code is reproducable\n",
    "    print(X_train_pre.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 2** \n",
    "\n",
    "We work with the [hand postures dataset](https://archive.ics.uci.edu/ml/datasets/Motion+Capture+Hand+Postures) in problem 2. This dataset has group structure. 14 users performing 5 hand postures with markers attached to a left-handed glove were recorded. Two different ML questions can be asked using this dataset. We will explore how the splitting and preprocessing differs for both questions in 2a and 2b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>User</th>\n",
       "      <th>X0</th>\n",
       "      <th>Y0</th>\n",
       "      <th>Z0</th>\n",
       "      <th>X1</th>\n",
       "      <th>Y1</th>\n",
       "      <th>Z1</th>\n",
       "      <th>X2</th>\n",
       "      <th>Y2</th>\n",
       "      <th>...</th>\n",
       "      <th>Z8</th>\n",
       "      <th>X9</th>\n",
       "      <th>Y9</th>\n",
       "      <th>Z9</th>\n",
       "      <th>X10</th>\n",
       "      <th>Y10</th>\n",
       "      <th>Z10</th>\n",
       "      <th>X11</th>\n",
       "      <th>Y11</th>\n",
       "      <th>Z11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>54.263880</td>\n",
       "      <td>71.466776</td>\n",
       "      <td>-64.807709</td>\n",
       "      <td>76.895635</td>\n",
       "      <td>42.462500</td>\n",
       "      <td>-72.780545</td>\n",
       "      <td>36.621229</td>\n",
       "      <td>81.680557</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56.527558</td>\n",
       "      <td>72.266609</td>\n",
       "      <td>-61.935252</td>\n",
       "      <td>39.135978</td>\n",
       "      <td>82.538530</td>\n",
       "      <td>-49.596509</td>\n",
       "      <td>79.223743</td>\n",
       "      <td>43.254091</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>55.849928</td>\n",
       "      <td>72.469064</td>\n",
       "      <td>-62.562788</td>\n",
       "      <td>37.988804</td>\n",
       "      <td>82.631347</td>\n",
       "      <td>-50.606259</td>\n",
       "      <td>78.451526</td>\n",
       "      <td>43.567403</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>55.329647</td>\n",
       "      <td>71.707275</td>\n",
       "      <td>-63.688956</td>\n",
       "      <td>36.561863</td>\n",
       "      <td>81.868749</td>\n",
       "      <td>-52.752784</td>\n",
       "      <td>86.320630</td>\n",
       "      <td>68.214645</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>55.142401</td>\n",
       "      <td>71.435607</td>\n",
       "      <td>-64.177303</td>\n",
       "      <td>36.175818</td>\n",
       "      <td>81.556874</td>\n",
       "      <td>-53.475747</td>\n",
       "      <td>76.986143</td>\n",
       "      <td>42.426849</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class  User         X0         Y0         Z0         X1         Y1  \\\n",
       "0      1     0  54.263880  71.466776 -64.807709  76.895635  42.462500   \n",
       "1      1     0  56.527558  72.266609 -61.935252  39.135978  82.538530   \n",
       "2      1     0  55.849928  72.469064 -62.562788  37.988804  82.631347   \n",
       "3      1     0  55.329647  71.707275 -63.688956  36.561863  81.868749   \n",
       "4      1     0  55.142401  71.435607 -64.177303  36.175818  81.556874   \n",
       "\n",
       "          Z1         X2         Y2  ...   Z8   X9   Y9   Z9  X10  Y10  Z10  \\\n",
       "0 -72.780545  36.621229  81.680557  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "1 -49.596509  79.223743  43.254091  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "2 -50.606259  78.451526  43.567403  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "3 -52.752784  86.320630  68.214645  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "4 -53.475747  76.986143  42.426849  ...  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "\n",
       "   X11  Y11  Z11  \n",
       "0  NaN  NaN  NaN  \n",
       "1  NaN  NaN  NaN  \n",
       "2  NaN  NaN  NaN  \n",
       "3  NaN  NaN  NaN  \n",
       "4  NaN  NaN  NaN  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/Postures.csv', skiprows=[1])\n",
    "df.replace(\"?\", np.nan, inplace=True)    # replace ? as nan\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 2a** (10 points)\n",
    "\n",
    "How would you prepare the data if we wanted to know how well we can predict the hand postures of a new, previously unseen user? Write down your reasoning (the usual 1-2 paragraphs are fine). Split the dataset into training, validation, and test sets, preprocess the sets, and loop through 10 random states similar to 1b. As usual, check for reproducability!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grading suggestion\n",
    "- 6 points if they do group-split based on user ID and use the 'class' (the hand gesture) as the target variable \n",
    "    - it's ok if they use something else than GroupShuffleSplit as long as they split based on user ID\n",
    "- 2 points for using the standard scaler on each 33 features and fitting on the train only\n",
    "- 2 points for looping through 10 random states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Add your explanation here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User in kfold: [ 1  2  4  5  6  7  8  9 11 13 14], user in test: [ 0 10 12]\n",
      "********************************************************************************\n",
      "User in kfold: [ 1  2  4  5  6  7  8  9 11 13 14], user in test: [ 0 10 12]\n",
      "********************************************************************************\n",
      "User in kfold: [ 0  2  4  6  7  8  9 10 11 12 13], user in test: [ 1  5 14]\n",
      "********************************************************************************\n",
      "User in kfold: [ 0  1  4  5  6  7  9 10 12 13 14], user in test: [ 2  8 11]\n",
      "********************************************************************************\n",
      "User in kfold: [ 0  1  2  4  5  6  7  8 10 12 13], user in test: [ 9 11 14]\n",
      "********************************************************************************\n",
      "User in kfold: [ 1  4  5  6  8  9 10 11 12 13 14], user in test: [0 2 7]\n",
      "********************************************************************************\n",
      "User in kfold: [ 1  4  5  7  8  9 10 11 12 13 14], user in test: [0 2 6]\n",
      "********************************************************************************\n",
      "User in kfold: [ 0  4  5  7  8  9 10 11 12 13 14], user in test: [1 2 6]\n",
      "********************************************************************************\n",
      "User in kfold: [ 0  1  2  5  6  8  9 10 11 13 14], user in test: [ 4  7 12]\n",
      "********************************************************************************\n",
      "User in kfold: [ 0  1  2  4  5  6  7  8  9 10 12], user in test: [11 13 14]\n",
      "********************************************************************************\n"
     ]
    }
   ],
   "source": [
    "# add your code here\n",
    "\n",
    "# save processed train-cv-test sets in a list of dictionaries\n",
    "data_after_split = []\n",
    "# extract X, y and User\n",
    "y = df['Class']\n",
    "User = df['User']\n",
    "X = df.iloc[:, 2:]\n",
    "# init GroupShuffleSplit as follows\n",
    "gss = GroupShuffleSplit(n_splits=10, train_size=.8, random_state=42)\n",
    "for nth_split, (other_idx, test_idx) in enumerate(gss.split(X, y, User)):    # group by User\n",
    "    # extract X_other, X_test, y_other, y_test, User_other, User_test\n",
    "    X_other, y_other = X.iloc[other_idx], y.iloc[other_idx]\n",
    "    X_test, y_test = X.iloc[test_idx], y.iloc[test_idx]\n",
    "    User_other = User.iloc[other_idx]\n",
    "    User_test = User.iloc[test_idx]\n",
    "    # init GroupKFold, 5 folds\n",
    "    gkf = GroupKFold(n_splits=5)\n",
    "    # create a temporary dictionary for kfold and test data\n",
    "    random_split_tmp = {'kfold_train':[], 'kfold_cv':[], 'test': []}\n",
    "    for train_idx, cv_idx in gkf.split(X_other, y_other, User_other):    # group by User_other\n",
    "        # extract X_train, X_train, y_cv, y_cv, User_train, User_cv\n",
    "        X_train, X_cv = X_other.iloc[train_idx], X_other.iloc[train_idx]\n",
    "        y_train, y_cv = y_other.iloc[cv_idx], y_other.iloc[cv_idx]\n",
    "        User_train = User_other.iloc[train_idx]\n",
    "        User_cv = User_other.iloc[cv_idx]\n",
    "        # check if ant user exist in any of the two splits\n",
    "        if set(User_train.unique()) == set(User_cv.unique()) or\\\n",
    "           set(User_train.unique()) == set(User_test.unique()) or\\\n",
    "           set(User_cv.unique()) == set(User_test.unique()):\n",
    "            raise ValueError('User exists in two or more of the splits')\n",
    "        # init StandardScaler\n",
    "        ss = StandardScaler()\n",
    "        # fit_transform on train\n",
    "        X_train = ss.fit_transform(X_train)\n",
    "        # transform cv and test\n",
    "        X_cv = ss.transform(X_train)\n",
    "        X_test = ss.transform(X_test)\n",
    "        # save to temp dict\n",
    "        random_split_tmp['kfold_train'].append([X_train, y_train])\n",
    "        random_split_tmp['kfold_cv'].append([X_cv, y_cv])\n",
    "        random_split_tmp['test'].append([X_test, y_test])\n",
    "    # save split of this random \n",
    "    data_after_split.append(random_split_tmp)\n",
    "    print(f'User in kfold: {User_other.unique()}, user in test: {User_test.unique()}')\n",
    "    print('*' * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 2b** (10 points)\n",
    "\n",
    "How would you prepare the data if we wanted to identify a user based on hand postures? Follow the same steps as in 2a (explain your reasoning, split, preprocess, loop through 10 random states, check reproducability)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grading suggestion\n",
    "- 6 points if they split based on the user as the target variable \n",
    "    - the perfect solution would be to do a stratified split based on the combination of class and user ID columns\n",
    "    - it is however also good if they do a stratified split on the user ID. this is important because some users have a few hundred postures measured while other uses have almost 10k postures.\n",
    "    - a simple train_test_split is not OK.\n",
    "- 2 points for using the standard scaler on each 33 features and fitting on the train only\n",
    "- 2 points for looping through 10 random states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25910     6\n",
      "16228     2\n",
      "65267    13\n",
      "8305      0\n",
      "53830    11\n",
      "Name: User, dtype: int64\n",
      "17023     2\n",
      "25270     6\n",
      "57502    12\n",
      "10190     1\n",
      "43975    10\n",
      "Name: User, dtype: int64\n",
      "59723    12\n",
      "27283     6\n",
      "29274     8\n",
      "35314     8\n",
      "57570    12\n",
      "Name: User, dtype: int64\n",
      "24797     6\n",
      "64001    13\n",
      "40741    10\n",
      "8219      0\n",
      "32388     8\n",
      "Name: User, dtype: int64\n",
      "37026     9\n",
      "47274    10\n",
      "73131    14\n",
      "28673     8\n",
      "3414      0\n",
      "Name: User, dtype: int64\n",
      "50498    11\n",
      "56563    11\n",
      "28933     8\n",
      "11495     1\n",
      "68504    13\n",
      "Name: User, dtype: int64\n",
      "28619     7\n",
      "604       0\n",
      "74272    14\n",
      "41497    10\n",
      "33372     8\n",
      "Name: User, dtype: int64\n",
      "14427    2\n",
      "39171    9\n",
      "16213    2\n",
      "15106    2\n",
      "20988    5\n",
      "Name: User, dtype: int64\n",
      "54546    11\n",
      "24060     6\n",
      "66064    13\n",
      "23562     5\n",
      "74710    14\n",
      "Name: User, dtype: int64\n",
      "29754     8\n",
      "28838     8\n",
      "13728     1\n",
      "58217    12\n",
      "77565    14\n",
      "Name: User, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# add you code here\n",
    "\n",
    "# save processed train-cv-test sets in a list of dictionaries\n",
    "data_after_split = []\n",
    "# extract X, y and Class\n",
    "y = df['User']\n",
    "X = df.iloc[:, 2:]\n",
    "# set strata reference as class & user id\n",
    "stratify_other_test_ref = df['Class'].astype(str) + \"&\" + df['User'].astype(str)\n",
    "for r in range(10):    # loop through 10 random states\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, random_state=42*r, stratify=stratify_other_test_ref)\n",
    "    # get strata reference for kfold\n",
    "    stratify_kfold_ref = stratify_other_test_ref.iloc[X_other.index]\n",
    "    # init kfold\n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "    # create a temporary dictionary for kfold and test data\n",
    "    random_split_tmp = {'kfold_train':[], 'kfold_cv':[], 'test': []}\n",
    "    for train_index, cv_index in skf.split(X_other, stratify_kfold_ref):\n",
    "        # extract X_train, X_train, y_cv, y_cv\n",
    "        X_train, X_cv = X_other.iloc[train_index], X_other.iloc[cv_index]\n",
    "        y_train, y_cv = y_other.iloc[train_index], y_other.iloc[cv_index]\n",
    "        # init StandardScaler\n",
    "        ss = StandardScaler()\n",
    "        # fit_transform on train\n",
    "        X_train = ss.fit_transform(X_train)\n",
    "        # transform cv and test\n",
    "        X_cv = ss.transform(X_train)\n",
    "        X_test = ss.transform(X_test)\n",
    "        # save to temp dict\n",
    "        random_split_tmp['kfold_train'].append([X_train, y_train])\n",
    "        random_split_tmp['kfold_cv'].append([X_cv, y_cv])\n",
    "    random_split_tmp['test'] = [X_test, y_test]\n",
    "    # save split of this random \n",
    "    data_after_split.append(random_split_tmp)\n",
    "    print(y_test.iloc[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
