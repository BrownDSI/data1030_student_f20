{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mud card and piazza questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **What material do you suggest us to refer to when we want to know the information about a package usage except for python documentation? For example, if I want to make some calculations inside the dataframe and I want to know if there are any functions or syntax I can use in pandas to help me save a lot of work.**\n",
    "    - stackoverlow\n",
    "    - google your problem e.g., 'pandas count unique elements in column'\n",
    "    - look for hits either on the pandas website or stackoverflow to find your solution\n",
    "    - like [this](https://stackoverflow.com/questions/45759966/counting-unique-values-in-a-column-in-pandas-dataframe-like-in-qlik/45760042) or [this](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.nunique.html)\n",
    "    - I've been coding in python for roughly 10 years and I did not come across a coding problem that was not already solved by someone on stackoverflow.\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Stepping back from EDA itself a bit, I was wondering about the formulation of a machine learning question. For example, I know in econometrics you are looking to understand causality. I think for machine learning, it is not limited to causality. I was hoping to have a better understanding of examples of questions we are trying to answer.**\n",
    "    - ML is mostly about predictive power and automatization\n",
    "    - If a task is repetitive and potentially labor-intensive for humans, an ML model might speed things up\n",
    "    - Examples:\n",
    "        - grading essays\n",
    "        - predict if a patient is sick or not based on medical data\n",
    "        - predict if a bank transaction is fraud or not\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **I am struggling with the use of the symbol \" . \" ; how can I identify when I should use the symbol in python?**\n",
    "    - you use the dot if you want to \n",
    "        - use a function from a package (e.g., pd.read_csv(), plt.plot())\n",
    "        - create an instance of a class or in other words an object (e.g., pd.DataFrame())\n",
    "        - use a method specific to an object (e.g., df.head(), df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **I was wondering what the common ways of dealing with missing values in our data is. I don't mean filling in the missing values, but just generally how can we visualize how much is missing, how much can we allow to be missing in order to proceed with building the model, and maybe whether there are any fast handy tricks/common strategies to deal with data with a lot of missing values that doesn't involve filling them in.**\n",
    "    - We cover simple techniques of dealing with missing values in week 4 and revisit again in November with three advanced techniques\n",
    "    - PS3 has one exercise on manipulating missing values in a dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **I'm still unsure about loading sql data into pandas df's. Should we load sql tables into local memory first and then load them as csv's?**\n",
    "    - I was indeed a bit vague about this because it depends on the type of SQL database you use (mySQL, postgreSQL, etc.)\n",
    "    - you need to establish a connection to a SQL database using e.g., `sqlalchemy`\n",
    "    - then you can submit standard SQL queries and save the output directly into a dataframe\n",
    "    - no need to load tables into local memory first, this approach is faster and more memory efficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Can you explain further how to fix a character encoding problem when loading in a csv file.**\n",
    "    - *pd.read_csv([path_to_file], encoding = 'utf-8')*\n",
    "    - [here](https://docs.python.org/3/library/codecs.html#standard-encodings) is a list of encoding supported by python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Since .loc and .iloc are almost the same when working with a range index, are there some cases when one is preferred over the other?**\n",
    "    - it's a matter of preference I think\n",
    "    - I am used to working with numpy arrays so iloc is easier for me to follow\n",
    "    - if you work with a large dataset and runtime is an issue, you should try and time both approaches and check if one is faster than the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Why is it that when I run code from**\n",
    "\n",
    "*print(df[(df['hours-per-week'] >= 60)&(df['education']=='Doctorate')].shape)*\n",
    "\n",
    "- **my outcome is (33,15) but the answer is 96 ? Am i formatting something wrong? I ran al the previous code from the lessons prior**\n",
    "    - 33 is the number of rows selected, and 15 is the number of columns\n",
    "    - you could do .shape[0] to get back the number of rows, and .shape[1] will give you the number of columns\n",
    "        - if the question is how many people fulfill a certain set of conditions, you need the number of rows because there is one row per person in the adult dataset.\n",
    "    - the second issue is that you are using adult_test.csv but the instruction asks you to use adult_train.csv\n",
    "    - be mindful of what dataset is loaded into which data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Is there a way to normalize the counts against the max in their respective categories instead of the sum of all the counts?**\n",
    "    - that's exctly what we did when the normalized count matrix was created\n",
    "    - *count_matrix_norm = count_matrix.div(count_matrix.sum(axis=1),axis=0)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **I was very confused on the third question about the size of df_merge, as I just was not sure where that data frame came from.**\n",
    "    - It's just some dummy data in the lecture notes in a form of python dictionaries which you need to convert into dataframes as part of the exercise\n",
    "    - let's go through it together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Is df1.merge(df2, how = 'right', on = 'ID') equivalent to df2.merge(df1, how = 'left', on = 'ID') ?**\n",
    "    - yes, but don't believe me, just try it.\n",
    "    - the column orders might be different but the two solutions are equivalent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **What is the real difference between a right and left merge, or are they essentially the same operation written in two ways? And is there a time to use one over the other?**\n",
    "- **I'm still a bit confused how exactly the merge method works. How do I know whether to use a left or a right merge?**\n",
    "- **Prior to doing a merge between dataframes, are there some criteria to consider as to which one is on the 'left' or the 'right'? Is it more important to just stay consistent once you choose?**\n",
    "    - `df1.merge(df2,how='left',on='ID')` - the merged dataframe will contain the IDs from df1\n",
    "    - `df1.merge(df2,how='right',on='ID')` - the merged dataframe will contain the IDs from df2\n",
    "    - which one you should use depends on the question you are trying to answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **It seems the 'merge' and 'join' functions in python are similar. Merge seems more versatile. When do you suggest using merge, and when join (if ever)?**\n",
    "    - I am pretty method-agnostic generally.\n",
    "    - As long as you answer the question correctly, you can use either, I have no preference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **One question I had was if it is a good idea to use Kernel Density Estimation for making heat-maps instead of histograms? I would imagine that it would produce a more smooth looking plot that would make the structure more visible.**\n",
    "    - Be careful with KDE because it can produce smooth but unrealistic figures\n",
    "    - E.g., salaries are smoothed into the negative range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **I had the most trouble with identifying the correct type of plot for different kinds of data (i.e. the last quiz before the last video)**\n",
    "- **The different plot part is a bit confusing. It takes some efforts to understand different types of data and which plot is best suited to visualize the data.**\n",
    "    - let's go through Quiz 5 together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **A cheat sheet that summarizes the key for each graphes and how to tune different features of the graph would be really helpful.**\n",
    "    - check out the matplotlib cheat sheet linked in the last cell of the lecture notes\n",
    "    - [Matplotlib cheatsheets](https://github.com/matplotlib/cheatsheets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **If I use %matplotlib inline after importing packages, I wonder whether plt.show() is still necessary**\n",
    "     - Me too. :) Try it without plt.show()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **In what situations would a box plot be preferable to a violin plot (and vis versa)?**\n",
    "    - both plot type is great to visualize a categorical vs. continuous features\n",
    "    - this is a subjective decision, depends on your preferences\n",
    "    - personally I prefer violin plots because it shows the distributions better\n",
    "    - others prefer the box plot because it is easier to read quantiles and percentiles off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **It would be helpful if you went through why certain graphs are better for continuous vs categorical data. I think this would help me remember which to use, with intuition, rather than refer back to a the chart as a reference.**\n",
    "    - create bad plots :)\n",
    "    - try to create a scatter plot using two categorical features, you'll see why this is bad.\n",
    "    - try to create a bar plot using a continuous feature, it won't look good because each value might be unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **In the visualizations, are you choosing a particular 'alpha' value, or testing different values to see what looks best?**\n",
    "    - I always experiment a bit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Also I'm wondering how to show a histogram's axis with log bins.**\n",
    "    - you need to manually create the log bins using for example `np.logspace` and then using `plt.semilogx()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **I'd also like some clarity on the nuts and bolts of the code that produces these 2D visualizations, particularly heatmaps.**\n",
    "    - the best way to go about that is to check the manuals of the plotting functions and play around with the arguments I use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **In your video example, there was a divide by zero error related to the log10 function. I got the same error on my system. Is that particular error something that could alter the visualization?**\n",
    "    - It doesn't alter the visualization, it just shows up as white squares\n",
    "    - If the warning bothers you, look for solutions to fix this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **The multiple columns plots didn't work for me so I'm still a little confused about how to change that code to suit what I want.**\n",
    "    - I'm not sure what's going on here but this is an excellent exercise to gain experience in debugging.\n",
    "    - Go ahead and investigate the issue and let me know when you found a fix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*pd.plotting.scatter_matrix(df.select_dtypes(int), figsize=(9, 9),*\n",
    "\n",
    "*c = pd.get_dummies(df['gross-income']).iloc[:,1],marker='o',hist_kwds={'bins': 50}, s=30, alpha=.1)*\n",
    "\n",
    "- **When should I use get_dummies to plot?**\n",
    "    - get_dummies is used to determine the colors of the points in the scatter matrix so you should use it if you want to prepare a plot using all continuous features and use one categorical feature to color the points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **For the purpose of this course is it enough that you are able to create the visualizations using external resources (like stackoverflow) or should you be able to code them without looking.**\n",
    "    - you can use any external resource!\n",
    "    - having said that, you will have a time limit during the exams so you need to be able to code sufficiently quickly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
