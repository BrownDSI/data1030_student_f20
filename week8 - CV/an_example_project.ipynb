{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## When the iid assumption breaks down\n",
    "- What is the intended use of the model? What is it supposed to do/predict?\n",
    "- What data do you have available at that time?\n",
    "- Your cross validation must simulate the intended use of the model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## An example: seizure project\n",
    "- you can read the publication [here](https://ieeexplore.ieee.org/document/8857552)\n",
    "- classification problem:\n",
    "   - epileptic seizures vs. non-epileptic psychogenic seizures\n",
    "- data from empatica wrist sensor\n",
    "   - heart rate, skin temperature, EDA, blood volume pressure, acceleration\n",
    "- data collection:\n",
    "   - patients come to the hospital for a few days\n",
    "   - eeg and video recording to determine seizure type\n",
    "   - wrist sensor data is collected\n",
    "- question:\n",
    "   - Can we use the wrist sensor data to differentiate the two seizure types on new patients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    patient ID            seizure_ID  ACC_mean  BVP_mean  EDA_mean    HR_mean  \\\n",
      "5           32  ID32__day3_arm_1_sz1  1.028539 -0.092102  0.112795  64.748167   \n",
      "6           32  ID32__day3_arm_1_sz1  1.027986  0.745437  0.130486  63.715667   \n",
      "7           32  ID32__day2_arm_1_sz0  1.002146  0.150810  0.189272  61.838500   \n",
      "8           32  ID32__day2_arm_1_sz0  1.005410  0.482859  1.226038  66.240833   \n",
      "9           32  ID32__day1_arm_1_sz0  0.997017 -0.925122  0.200990  56.103667   \n",
      "10          32  ID32__day1_arm_1_sz0  1.009207  1.618456  1.679754  64.668167   \n",
      "27          32  ID32__day1_arm_1_sz0  1.000290  0.046690  0.123165  54.289500   \n",
      "28          32  ID32__day1_arm_1_sz0  1.010351  0.125039  0.471180  65.060667   \n",
      "29          32  ID32__day2_arm_1_sz0  1.018163  0.254302  0.206010  61.875833   \n",
      "30          32  ID32__day2_arm_1_sz0  1.016785  1.242893  0.954649  66.216167   \n",
      "34          32  ID32__day3_arm_1_sz1  1.008867  0.070180  0.195966  65.995667   \n",
      "35          32  ID32__day3_arm_1_sz1  1.009554  0.222872  0.229909  63.871000   \n",
      "58          32  ID32__day3_arm_1_sz0  1.008873 -0.550857  0.177822  67.750833   \n",
      "79          32  ID32__day3_arm_1_sz0  1.026840  0.355953  0.205273  69.124667   \n",
      "\n",
      "    TEMP_mean  ACC_stdev   BVP_stdev  EDA_stdev  ...  BVP_50th  EDA_50th  \\\n",
      "5   36.944833   0.007469   36.486091   0.003905  ...     1.815  0.112710   \n",
      "6   36.676333   0.028190   84.964155   0.018598  ...     2.210  0.131921   \n",
      "7   38.600333   0.003747   64.194294   0.024278  ...     6.985  0.186026   \n",
      "8   39.296083   0.035257  165.665784   0.891139  ...     1.140  1.062333   \n",
      "9   34.656667   0.022648   77.013336   0.132008  ...     3.800  0.142159   \n",
      "10  34.678000   0.046047  146.515297   0.438236  ...     5.585  1.690537   \n",
      "27  38.467417   0.019826   51.176639   0.014530  ...     7.765  0.124259   \n",
      "28  38.448000   0.077142   61.205657   0.156170  ...     3.290  0.510114   \n",
      "29  37.681583   0.006805   40.982246   0.017099  ...     1.455  0.202632   \n",
      "30  37.979500   0.032493  219.277839   0.612229  ...    -5.785  1.028171   \n",
      "34  40.659458   0.021812   49.981175   0.013259  ...     3.480  0.198570   \n",
      "35  40.481333   0.048531   37.409681   0.031963  ...     0.695  0.228676   \n",
      "58  39.906667   0.021431   27.472002   0.003085  ...     1.955  0.178073   \n",
      "79  34.490167   0.008165   40.742936   0.003550  ...     3.090  0.206207   \n",
      "\n",
      "    HR_50th  TEMP_50th  ACC_75th  BVP_75th  EDA_75th  HR_75th  TEMP_75th  \\\n",
      "5    65.060      36.95  1.029947   16.3725  0.115591  65.8175     36.990   \n",
      "6    62.175      36.81  1.029947   21.1625  0.147611  66.2100     36.840   \n",
      "7    61.840      38.61  1.006085   43.8850  0.209086  61.9000     38.790   \n",
      "8    62.325      39.37  1.008872   49.4325  2.313129  71.0625     39.390   \n",
      "9    56.110      34.66  0.996821   35.2700  0.176739  56.6050     34.660   \n",
      "10   65.790      34.66  1.021497   70.4800  1.998868  67.7725     34.735   \n",
      "27   53.960      38.49  1.002073   39.8525  0.133226  54.7425     38.500   \n",
      "28   65.285      38.45  1.014302   25.4625  0.577047  69.4975     38.530   \n",
      "29   61.910      37.68  1.022811   29.2125  0.219282  61.9300     37.750   \n",
      "30   64.700      38.00  1.022811   65.5000  1.503002  69.5725     38.030   \n",
      "34   66.145      40.68  1.013700   13.1300  0.199852  67.0425     40.710   \n",
      "35   64.395      40.49  1.016106   12.9650  0.260383  65.9625     40.530   \n",
      "58   68.170      39.93  1.015264   17.8625  0.179354  68.5725     40.030   \n",
      "79   69.810      34.37  1.033260   13.4550  0.207488  70.0000     34.680   \n",
      "\n",
      "    label  \n",
      "5     0.0  \n",
      "6     0.0  \n",
      "7     0.0  \n",
      "8     0.0  \n",
      "9     0.0  \n",
      "10    0.0  \n",
      "27    0.0  \n",
      "28    0.0  \n",
      "29    0.0  \n",
      "30    0.0  \n",
      "34    0.0  \n",
      "35    0.0  \n",
      "58    0.0  \n",
      "79    0.0  \n",
      "\n",
      "[14 rows x 48 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('data/seizure_data.csv')\n",
    "print(df[df['patient ID'] == 32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balance: 0.6884057971014492\n"
     ]
    }
   ],
   "source": [
    "y = df['label']\n",
    "patient_ID = df['patient ID']\n",
    "seizure_ID = df['seizure_ID']\n",
    "X = df.drop(columns=['patient ID','seizure_ID','label'])\n",
    "classes, counts = np.unique(y,return_counts=True)\n",
    "print('balance:',np.max(counts/len(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def ML_pipeline_kfold_GridSearchCV(X,y,random_state,n_folds):\n",
    "    # create a test set\n",
    "    X_other, X_test, y_other, y_test = train_test_split(X, y, test_size=0.2, random_state = random_state,stratify=y)\n",
    "    # splitter for _other\n",
    "    kf = StratifiedKFold(n_splits=n_folds,shuffle=True,random_state=random_state)\n",
    "    # create the pipeline: preprocessor + supervised ML method\n",
    "    scaler = StandardScaler()\n",
    "    pipe = make_pipeline(scaler,SVC())\n",
    "    # the parameter(s) we want to tune\n",
    "    param_grid = {'svc__C': np.logspace(-3,4,num=8),'svc__gamma': np.logspace(-3,4,num=8)}\n",
    "    # prepare gridsearch\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid,scoring = make_scorer(accuracy_score),\n",
    "                        cv=kf, return_train_score = True)\n",
    "    # do kfold CV on _other\n",
    "    grid.fit(X_other, y_other)\n",
    "    return grid, grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svc__C': 1.0, 'svc__gamma': 0.01}\n",
      "best CV score: 0.9227272727272726\n",
      "test score: 0.9285714285714286\n",
      "{'svc__C': 10.0, 'svc__gamma': 0.01}\n",
      "best CV score: 0.9363636363636363\n",
      "test score: 0.9285714285714286\n",
      "{'svc__C': 10.0, 'svc__gamma': 0.01}\n",
      "best CV score: 0.9045454545454547\n",
      "test score: 0.9464285714285714\n",
      "{'svc__C': 10.0, 'svc__gamma': 0.01}\n",
      "best CV score: 0.9\n",
      "test score: 0.9285714285714286\n",
      "{'svc__C': 10.0, 'svc__gamma': 0.01}\n",
      "best CV score: 0.9363636363636363\n",
      "test score: 0.9107142857142857\n",
      "test accuracy: 0.93 +/- 0.01\n"
     ]
    }
   ],
   "source": [
    "test_scores = []\n",
    "for i in range(5):\n",
    "    grid, test_score = ML_pipeline_kfold_GridSearchCV(X,y,i*42,5)\n",
    "    print(grid.best_params_)\n",
    "    print('best CV score:',grid.best_score_)\n",
    "    print('test score:',test_score)\n",
    "    test_scores.append(test_score)\n",
    "print('test accuracy:',np.around(np.mean(test_scores),2),'+/-',np.around(np.std(test_scores),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## This is wrong! A very bad case of data leakage!\n",
    "- the textbook case of information leakage!\n",
    "- if we just do KFold CV blindly, the points from the same patient end up in different sets\n",
    "   - when you deploy the model and apply it to data from new patients, that patient's data will be seen for the first time\n",
    "- the ML pipeline needs to mimic the intended use of the model!\n",
    "   - we want to split the points based on the patient ID!\n",
    "   - we want all points from the same patient to be in either train/CV/test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Group-based split: GroupKFold\n",
    "<center><img src=\"figures/groupkfold.png\" width=\"600\"></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "def ML_pipeline_groups_GridSearchCV(X,y,groups,random_state,n_folds):\n",
    "    # create a test set based on groups\n",
    "    splitter = GroupShuffleSplit(n_splits=1,test_size=0.2,random_state=random_state)\n",
    "    for i_other,i_test in splitter.split(X, y, groups):\n",
    "        X_other, y_other, groups_other = X.iloc[i_other], y.iloc[i_other], groups.iloc[i_other]\n",
    "        X_test, y_test, groups_test = X.iloc[i_test], y.iloc[i_test], groups.iloc[i_test]\n",
    "    # check the split\n",
    "#     print(pd.unique(groups))\n",
    "#     print(pd.unique(groups_other))\n",
    "#     print(pd.unique(groups_test))\n",
    "    # splitter for _other\n",
    "    kf = GroupKFold(n_splits=n_folds)\n",
    "    # create the pipeline: preprocessor + supervised ML method\n",
    "    scaler = StandardScaler()\n",
    "    pipe = make_pipeline(scaler,SVC())\n",
    "    # the parameter(s) we want to tune\n",
    "    param_grid = {'svc__C': np.logspace(-3,4,num=8),'svc__gamma': np.logspace(-3,4,num=8)}\n",
    "    # prepare gridsearch\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid,scoring = make_scorer(accuracy_score),\n",
    "                        cv=kf, return_train_score = True)\n",
    "    # do kfold CV on _other\n",
    "    grid.fit(X_other, y_other, groups=groups_other)\n",
    "    return grid, grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svc__C': 10.0, 'svc__gamma': 0.001}\n",
      "best CV score: 0.7609139784946237\n",
      "test score: 0.6410256410256411\n",
      "{'svc__C': 0.1, 'svc__gamma': 0.01}\n",
      "best CV score: 0.6522727272727272\n",
      "test score: 0.2711864406779661\n",
      "{'svc__C': 10.0, 'svc__gamma': 0.001}\n",
      "best CV score: 0.5720073891625616\n",
      "test score: 0.9390243902439024\n",
      "{'svc__C': 10.0, 'svc__gamma': 0.001}\n",
      "best CV score: 0.7061742424242425\n",
      "test score: 0.43243243243243246\n",
      "{'svc__C': 10000.0, 'svc__gamma': 0.001}\n",
      "best CV score: 0.6082407407407406\n",
      "test score: 0.8901098901098901\n",
      "test accuracy: 0.63 +/- 0.26\n"
     ]
    }
   ],
   "source": [
    "test_scores = []\n",
    "for i in range(5):\n",
    "    grid, test_score = ML_pipeline_groups_GridSearchCV(X,y,patient_ID,i*42,5)\n",
    "    print(grid.best_params_)\n",
    "    print('best CV score:',grid.best_score_)\n",
    "    print('test score:',test_score)\n",
    "    test_scores.append(test_score)\n",
    "print('test accuracy:',np.around(np.mean(test_scores),2),'+/-',np.around(np.std(test_scores),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The takeaway\n",
    "- an incorrect cross validation pipeline gives misleading results\n",
    "   - usually the model appears to be pretty accurate\n",
    "   - but the performance is poor when the model is deployed\n",
    "- this can be avoided by a careful cross validation pipeline\n",
    "   - think about how your model will be used\n",
    "   - mimic that future use in CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Data leakage in time series data is similar!\n",
    "- do NOT use information in CV which will not be available once your model is deployed\n",
    "   - don't use future information!\n",
    "   \n",
    "<center><img src=\"figures/timeseriessplit.png\" width=\"600\"></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
