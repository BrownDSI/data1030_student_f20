{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluation metrics in supervised ML, part 1, classification\n",
    "By the end of this lecture, you will be able to\n",
    "- Describe the terms in the confusion matrix\n",
    "- Summarize and compare derived metrics (e.g., accuracy, recall, precision, f score)\n",
    "- Choose a metric most appropriate for your problem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The supervised ML pipeline\n",
    "The goal: Use the training data (X and y) to develop a <font color='red'>model</font> which can <font color='red'>accurately</font> predict the target variable (y_new') for previously unseen data (X_new).\n",
    "\n",
    "**1. Exploratory Data Analysis (EDA)**: you need to understand your data and verify that it doesn't contain errors\n",
    "   - do as much EDA as you can!\n",
    "    \n",
    "**2. Split the data into different sets**: most often the sets are train, validation, and test (or holdout)\n",
    "   - practitioners often make errors in this step!\n",
    "   - you can split the data randomly, based on groups, based on time, or any other non-standard way if necessary to answer your ML question\n",
    "\n",
    "**3. Preprocess the data**: ML models only work if X and Y are numbers! Some ML models additionally require each feature to have 0 mean and 1 standard deviation (standardized features)\n",
    "   - often the original features you get contain strings (for example a gender feature would contain 'male', 'female', 'non-binary', 'unknown') which needs to transformed into numbers\n",
    "   - often the features are not standardized (e.g., age is between 0 and 100) but it needs to be standardized\n",
    "    \n",
    "<span style=\"background-color: #FFFF00\">**4. Choose an evaluation metric**: depends on the priorities of the stakeholders</span>\n",
    "   - often requires quite a bit of thinking and ethical considerations\n",
    "     \n",
    "**5. Choose one or more ML techniques**: it is highly recommended that you try multiple models\n",
    "   - start with simple models like linear or logistic regression\n",
    "   - try also more complex models like nearest neighbors, support vector machines, random forest, etc.\n",
    "    \n",
    "**6. Tune the hyperparameters of your ML models (aka cross-validation)**\n",
    "   - ML techniques have hyperparameters that you need to optimize to achieve best performance\n",
    "   - for each ML model, decide which parameters to tune and what values to try\n",
    "   - loop through each parameter combination\n",
    "       - train one model for each parameter combination\n",
    "       - evaluate how well the model performs on the validation set\n",
    "   - take the parameter combo that gives the best validation score\n",
    "   - evaluate that model on the test set to report how well the model is expected to perform on previously unseen data\n",
    "    \n",
    "**7. Interpret your model**: black boxes are often not useful\n",
    "   - check if your model uses features that make sense (excellent tool for debugging)\n",
    "   - often model predictions are not enough, you need to be able to explain how the model arrived to a particular prediction (e.g., in health care)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Let's start\n",
    "- decide what metric we will use to evaluate the supervised ML model \n",
    "   - this is necessary even before we train the model\n",
    "   - we need to know what single number metric we will use to compare models and to select the best one\n",
    "- sklearn classifiers have two methods to return predictions\n",
    "   - .predict_proba which returns the probability that the point belongs to each class with shape (n_samples, n_classes)\n",
    "   - .predict which returns the predicted class for each point with shape (n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### .predict_proba vs. .predict\n",
    "\n",
    "`y_true = [1 0 1 1 0] # the true labels`\n",
    "\n",
    "`pred_probs = \n",
    "[[0.02796171 0.97203829]\n",
    " [0.89682444 0.10317556]\n",
    " [0.50104129 0.49895871]\n",
    " [0.13713222 0.86286778]\n",
    " [0.95707434 0.04292566]] # predicted probabilities show the model's confidence`\n",
    " \n",
    " `y_pred = [1 0 0 1 0] # predicted class`\n",
    " - pred_probs\n",
    "    - first column is the probability that the point belongs to class 0\n",
    "    - second column is the probability that the point belings to class 1\n",
    "    - the rows sum to 1\n",
    " - y_pred\n",
    "    - 0 if class 0 probability is equal or larger than 50% (or equivalently if class 1 probability is less than 50%)\n",
    "    - 1 if class 0 probability is less than 50% (or equivalently of class 1 probability is equal or larger than 50%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### How to transform predicted probabilities to predicted class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 1 1 0 1 0 1]\n",
      "[0 1 1 0 0 1 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "y_true = np.array([0,0,1,0,1,1,0,1,0,1]) # the true classification labels of the dataset\n",
    "# pred_probs_class1 is the second column of pred_probs\n",
    "pred_probs_class1 = np.array([0.3, 0.7,  0.55, 0.12, 0.45, 0.89, 0.41, 0.02, 0.29, 0.85])\n",
    "p_crit =  0.5\n",
    "\n",
    "# If predicted probability is < p_crit (by default 0.5), predicted class is 0, otherwise it is 1.\n",
    "y_pred = np.zeros(len(pred_probs_class1),dtype=int)\n",
    "y_pred[pred_probs_class1 < p_crit] = 0\n",
    "y_pred[pred_probs_class1 >= p_crit] = 1\n",
    "\n",
    "print(y_true)\n",
    "print(y_pred) # the predicted classification labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For now, we focus on evaluation metrics applicable to predicted classes!\n",
    "\n",
    "We work with y_true and y_pred arrays.\n",
    "\n",
    "Next, we will work with metrics applicable to pred_probs and regression problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <font color='LIGHTGRAY'>Evaluation metrics in supervised ML, part 1, classification</font>\n",
    "<font color='LIGHTGRAY'>By the end of this lecture, you will be able to</font>\n",
    "- **Describe the terms in the confusion matrix**\n",
    "- <font color='LIGHTGRAY'>Summarize and compare derived metrics (e.g., accuracy, recall, precision, f score)</font>\n",
    "- <font color='LIGHTGRAY'>Choose a metric most appropriate for your problem</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The confusion matrix\n",
    "\n",
    "`y_true = [0, 0, 1, 0, 1, 1, 0, 1, 0, 1] # the true classification labels of the dataset`\n",
    "\n",
    "`y_pred = [0, 1, 1, 0, 0, 1, 0, 0, 0, 1] # the predicted classification labels`\n",
    "\n",
    "Let's count how many points we have in four categories:\n",
    "\n",
    "- true label is 0, predicted label is 0 - **True Negatives**\n",
    "- true label is 1, predicted label is 1 - **True Positives**\n",
    "- true label is 0, predicted label is 1 - **False Positive**\n",
    "- true label is 1, predicted label is 0 - **False Negative**\n",
    "\n",
    "Generally, the confusion matrix $C$ is such that $C_{i,j}$ is equal to the number of observations known to be in group $i$ but predicted to be in group $j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Back to our example:\n",
    "\n",
    "`y_true = [0, 0, 1, 0, 1, 1, 0, 1, 0, 1] # the true classification labels of the dataset`\n",
    "\n",
    "`y_pred = [0, 1, 1, 0, 0, 1, 0, 0, 0, 1] # the predicted classification labels`\n",
    "\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td colspan=\"2\" rowspan=\"2\"></td>\n",
    "        <td colspan=\"2\">Predicted class</td>\t\t\t\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Predicted Negative (0)</td>\n",
    "        <td>Predicted Positive (1)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td rowspan=\"2\">Actual class</td>\n",
    "        <td>Condition Negative (0)</td>\n",
    "        <td><b>True Negative (TN): 4</b></td>\n",
    "        <td><b>False Positive (FP): 1</b></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Condition Positive (1)</td>\n",
    "        <td><b>False Negative (FN): 2</b></td>\n",
    "        <td><b>True Positive (TP): 3</b></td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## In sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 1]\n",
      " [2 3]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = [0,0,1,0,1,1,0,1,0,1]\n",
    "y_pred = [0,1,1,0,0,1,0,0,0,1]\n",
    "print(confusion_matrix(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = np.array(classes)\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        \n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(y_true,y_pred,classes=['class 0','class 1'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Quiz 1\n",
    "\n",
    "Calculate what fraction of the data points are correctly classified in the example below. Visualize the confusion matrix (not part of the quiz)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array([0,0,2,1,1,0,2,2,2,0,1,1,0,0,0,1])\n",
    "y_pred = np.array([0,1,0,1,0,0,2,2,1,0,1,1,0,0,1,2])\n",
    "\n",
    "# add you code below\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <font color='LIGHTGRAY'>Evaluation metrics in supervised ML, part 1, classification</font>\n",
    "<font color='LIGHTGRAY'>By the end of this lecture, you will be able to</font>\n",
    "- <font color='LIGHTGRAY'>Describe the terms in the confusion matrix</font>\n",
    "- **Summarize and compare derived metrics (e.g., accuracy, recall, precision, f score)**\n",
    "- <font color='LIGHTGRAY'>Choose a metric most appropriate for your problem</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Metrics derived from $C$\n",
    "$C$ contains $n_{classes}^2$ elements but we need a single number metric to easily compare various models.\n",
    "\n",
    "For two classes:\n",
    "\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td colspan=\"2\" rowspan=\"2\"></td>\n",
    "        <td colspan=\"2\">Predicted class</td>\t\t\t\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Predicted Negative (0)</td>\n",
    "        <td>Predicted Positive (1)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td rowspan=\"2\">Actual class</td>\n",
    "        <td>Condition Negative (0)</td>\n",
    "        <td><b>True Negative (TN)</b></td>\n",
    "        <td><b>False Positive (FP)</b></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Condition Positive (1)</td>\n",
    "        <td><b>False Negative (FN)</b></td>\n",
    "        <td><b>True Positive (TP)</b></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "Some single number metrics derived from $C$:\n",
    "- accuracy: fraction of data points correctly classified\n",
    "   - $a = \\sum_i C_{i,i} / \\sum C$ = (TP + TN) / (TP + TN + FP + FN)\n",
    "- recall: what fraction of the condition positive samples are true positives?\n",
    "   - it measures the ability of the classifier to identify all positive samples\n",
    "   - in binary classification: R = TP / (TP + FN)\n",
    "- precision: what fraction of the predicted positive points are true positives?\n",
    "   - it measures the ability of the classifier to not predict a negative sample to be positive\n",
    "   - in binary classification: P = TP / (TP + FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td colspan=\"2\" rowspan=\"2\"></td>\n",
    "        <td colspan=\"2\">Predicted class</td>\t\t\t\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Predicted Negative (0)</td>\n",
    "        <td>Predicted Positive (1)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td rowspan=\"2\">Actual class</td>\n",
    "        <td>Condition Negative (0)</td>\n",
    "        <td><b>True Negative (TN)</b></td>\n",
    "        <td><b>False Positive (FP)</b></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Condition Positive (1)</td>\n",
    "        <td><b>False Negative (FN)</b></td>\n",
    "        <td><b>True Positive (TP)</b></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "A = (TP + TN) / (TP + TN + FP + FN) \n",
    "\n",
    "R = TP / (TP + FN) = TP / CP\n",
    "\n",
    "P = TP / (TP + FP) = TP / PP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The f_beta score\n",
    "Weighted harmonic mean of P and R:\n",
    "### <center> $f_{\\beta} = (1 + \\beta^2) \\frac{P R}{\\beta^2 P + R}$ </center>\n",
    "\n",
    "If $\\beta = 1$, we have the f1 score:\n",
    "### <center> $f_{1} = 2 \\frac{P R}{P + R}$ </center>\n",
    "\n",
    "If $\\beta < 1$, more weight to precision.\n",
    "\n",
    "If $\\beta > 1$, more weight to recall.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The scores are a function of p_crit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 1 1 0 1 0 1]\n",
      "[0 1 1 0 0 1 0 0 0 1]\n",
      "accuracy 0.7\n",
      "recall 0.6\n",
      "precision 0.75\n",
      "f1 0.6666666666666665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/azsom/opt/anaconda3/envs/data1030/lib/python3.7/site-packages/sklearn/utils/validation.py:71: FutureWarning: Pass beta=1 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, fbeta_score\n",
    "\n",
    "y_true = np.array([0,0,1,0,1,1,0,1,0,1]) # the true classification labels of the dataset\n",
    "y_pred_proba = np.array([0.3, 0.7,  0.55, 0.12, 0.45, 0.89, 0.41, 0.02, 0.29, 0.85])\n",
    "\n",
    "p_crit = 0.5\n",
    "\n",
    "y_pred = np.zeros(len(y_pred_proba),dtype=int)\n",
    "y_pred[y_pred_proba < p_crit] = 0\n",
    "y_pred[y_pred_proba >= p_crit] = 1\n",
    "\n",
    "print(y_true)\n",
    "print(y_pred) # the predicted classification labels\n",
    "print('accuracy',accuracy_score(y_true,y_pred))\n",
    "print('recall',recall_score(y_true,y_pred))\n",
    "print('precision',precision_score(y_true,y_pred))\n",
    "print('f1',fbeta_score(y_true,y_pred,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Quiz 2\n",
    "Given the true and predicted labels, what are the accuracy, recall, precision, and f1 scores? \n",
    "\n",
    "Do not use sklearn to answer the question! First construct the confusion matrix and then calculate the scores by hand!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [0,0,0,1,1,1,0,0]\n",
    "y_pred = [0,1,0,1,1,0,0,0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <font color='LIGHTGRAY'>Evaluation metrics in supervised ML, part 1, classification</font>\n",
    "<font color='LIGHTGRAY'>By the end of this lecture, you will be able to</font>\n",
    "- <font color='LIGHTGRAY'>Describe the terms in the confusion matrix</font>\n",
    "- <font color='LIGHTGRAY'>Summarize and compare derived metrics (e.g., accuracy, recall, precision, f score)</font>\n",
    "- **Choose a metric most appropriate for your problem**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How should you choose a metric?\n",
    "\n",
    "- What are the terms in the confusion matrix that you most (or least) care about?\n",
    "    - In an imbalanced dataset, TNs are large so you should use a metric that doesn't include TN\n",
    "    - no accuracy\n",
    "    - f score is usually preferred if your dataset is imbalanced\n",
    "- Will we act (intervene/apply treatment) on the model's prediction?\n",
    "    - Is it cheap to act? (e.g., mass email)\n",
    "       - we want to capture the largest fraction of the condition positive samples even if FPs will be large as a result\n",
    "       - recall or fbeta with beta > 1 (f1.5 or f2 are often used)\n",
    "    - Is it expensive to act? Do we have limited resources? Or treatment/action is costly?\n",
    "       - we want to make sure that the resources are allocated the best way possible\n",
    "       - want to make sure that a large fraction of the predicted positives are  true positives\n",
    "       - precision or fbeta with beta < 1 (f0.5 is often used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
