{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick recap of deadlines\n",
    "- check the pinned piazza messages!\n",
    "- Final project submission deadline is December 2, 11:59pm - no late submissions for this one!\n",
    "- Final project presentations are on December 3 and 4.\n",
    "    - Please sign up for a slot if you haven't done so already!\n",
    "- Final exam is on December 10, 10am to noon.\n",
    "- Expect grades around December 14-15\n",
    "    - I will post the point distribution on piazza once the grades are final\n",
    "    - I will reach out to you personally in an email if your grade is not an A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mud card questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AB testing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Why is random selection not used for selecting points for samples?**\n",
    "    - if you get unlucky, the measured difference between group A and group B will be solely attributed to the randomness in sampling\n",
    "    - this is why you want to make sure that the sample properties are as close to each other as possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **what should be the structure of sample A and sample B? In other words, do they only represent one column of the predicted results based on the corresponding models? e.g. sample A: the y_pred_previous model. sample B: the y_pred_current model.**\n",
    "    - usually it is not the predictions but whether or not the model was correct for those datapoints, so it's a combination of y_trues and y_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **How to avoid taking too much time doing test but also get a pretty accurate result?**\n",
    "    - I'm not aware of any magic tricks unfortunately\n",
    "    - accuracte results will take generally longer to obtain\n",
    "    - sometimes waiting for the test results to come in will take months or years (e.g., healthcare)\n",
    "    - sometimes the test results come in in a day (e.g., recommender systems on amazon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **I know you mentioned that it is a bit tricky to choose a statistical test - is there any test that is specifically off limits? I guess I am wondering if any of the steps mentioned after that of choosing the test are dependent on the test itself**\n",
    "    - I haven't done AB testing all that often but my experience is that all statistical tests return a p value so the steps after choosing the test should be the same regardless of the test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **What do most people seem to miss between completing machine learning process and then A/B testing? What are common things to not do before those steps?**\n",
    "    - before you start AB testing, collect more recent data and check how your model performs on it.\n",
    "    - if the performance on this new dataset is similar to what it was on the historical dataset, proceed with AB testing\n",
    "    - otherwise figure out what went wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Could you talk a little bit more about the code from the 'Estimating the Sample Size' video? Specifically the stats.fisher_exact() part. I read the fisher test wikipedia page but more info could be helpful. Is fisher test the standard test used for A/B testing for classification problems. Also where would B_acc = .85 come from? Is this the test score calculated when building the model?**\n",
    "    - this is the typical example when I talked to my statistician friend, described the problem, and he recommended I go with Fisher's exact test.\n",
    "    - I am not sure if it is the standard test for AB testing a classification problem, I haven't done enough AB testing to know\n",
    "    - B_acc is exactly the test score you calculated when building the model\n",
    "    - keep in mind, the code calculates estimates and expectations based on the test score. \n",
    "    - the model performance might not hold up during testing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **in your a/b example with alumni donations, what were the features?**\n",
    "    - donation history, stuff we knew about the alumni from the time when they were students like graduation year, department, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **I have a philosophical question about machine learning models: If we find that we need to adjust a model after we see new data coming in, then does that lead us to say that the previous model, which was slightly different, was \"wrong?\"**\n",
    "    - If the properties of the new incoming data change, your model needs to change too otherwise your predictions will be inaccuracte\n",
    "    - The old model was good for the old dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Would you recommend taking an elective in an AB testing stats course. In industry how beneficial would this elective be?**\n",
    "    - if you are interested in AB testing and you'd enjoy working in this area, then yes\n",
    "    - lots of companies hire data scientists to do only AB testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **I actually want to review the video during the winter break, I am wondering will canvas still be here at that time?**\n",
    "    - As long as you have Brown credentials, you'll be able to watch the videos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Quiz 1 and PS9**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
